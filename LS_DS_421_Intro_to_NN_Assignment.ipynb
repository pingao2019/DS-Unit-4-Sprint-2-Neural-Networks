{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LS_DS_421_Intro_to_NN_Assignment.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pingao2019/DS-Unit-4-Sprint-2-Neural-Networks/blob/master/LS_DS_421_Intro_to_NN_Assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "dVfaLrjLvxvQ"
      },
      "source": [
        "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
        "<br></br>\n",
        "<br></br>\n",
        "\n",
        "# Neural Networks\n",
        "\n",
        "## *Data Science Unit 4 Sprint 2 Assignment 1*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "wxtoY12mwmih"
      },
      "source": [
        "## Define the Following:\n",
        "You can add image, diagrams, whatever you need to ensure that you understand the concepts below.\n",
        "\n",
        "### Input Layer:initial data for the neural network.\n",
        "\n",
        "### Hidden Layer:— intermediate layer between input and output layer and place where all the computation is done.\n",
        "\n",
        "### Output Layer:— produce the result for given inputs\n",
        "\n",
        "### Neuron: a neuron is a mathematical function that model the functioning.  Typically, a neuron compute the weighted average of its input, and this sum is passed through a nonlinear function, often called activation function, such as the sigmoid.\n",
        "\n",
        "### Weight:\n",
        "\n",
        "### Activation Function:Typically, a neuron compute the weighted average of its input, and this sum is passed through a nonlinear function, often called activation function, such as the sigmoid.\n",
        "\n",
        "### Node Map:A node, also called a neuron or Perceptron, is a computational unit that has one or more weighted input connections, a transfer function that combines the inputs in some way, and an output connection. Nodes are then organized into layers to comprise a network. A Hopfield network (HN) is a network where every neuron is connected to every other neuron; it is a completely entangled plate of spaghetti as even all the nodes function as everything. Each node is input before training, then hidden during training and output afterwards\n",
        "\n",
        "### Perceptron:\n",
        "The first and simplest kind of neural network that we could talk about is the perceptron. A perceptron is just a single node or neuron of a neural network with nothing else. It can take any number of inputs and spit out an output. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "NXuy9WcWzxa4"
      },
      "source": [
        "## Inputs -> Outputs\n",
        "\n",
        "### Explain the flow of information through a neural network from inputs to outputs. Be sure to include: inputs, weights, bias, and activation functions. How does it all flow from beginning to end?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "PlSwIJMC0A8F"
      },
      "source": [
        "#### My Answer:\n",
        " Input Layer has the initial data for the neural network.# Hidden Layer-intermediate layer between input and output layer and place where all the computation is done. Output Layer produce the result for given inputs. : a neuron is a mathematical function that model the functioning.  Typically, a neuron compute the weighted average of its input, and this sum is passed through a nonlinear function, often called activation function, such as the sigmoid.A node, also called a neuron or Perceptron, is a computational unit that has one or more weighted input connections, a transfer function that combines the inputs in some way, and an output connection. Nodes are then organized into layers to comprise a network. Sometimes every neuron is connected to every other neuron; it is a completely entangled plate of spaghetti as even all the nodes function as everything. Each node is input before training, then hidden during training and output afterwards. The first and simplest kind of neural network that we could talk about is the perceptron. A perceptron is just a single node or neuron of a neural network with nothing else. It can take any number of inputs and spit out an output. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "6sWR43PTwhSk"
      },
      "source": [
        "## Write your own perceptron code that can correctly classify (99.0% accuracy) a NAND gate. \n",
        "\n",
        "| x1 | x2 | y |\n",
        "|----|----|---|\n",
        "| 0  | 0  | 1 |\n",
        "| 1  | 0  | 1 |\n",
        "| 0  | 1  | 1 |\n",
        "| 1  | 1  | 0 |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pb12xEjR9pdW",
        "colab_type": "text"
      },
      "source": [
        "Establish training data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LlhrM9s88Z-_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "data = { 'x1': [0,1,0,1],\n",
        "         'x2': [0,0,1,1],\n",
        "         'y':  [1,1,1,0]\n",
        "       }\n",
        "\n",
        "df = pd.DataFrame.from_dict(data).astype('int')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Sgh7VFGwnXGH",
        "outputId": "e5afa1d5-64d3-4c44-bd17-ff53257f4a1e",
        "colab": {}
      },
      "source": [
        "df"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>x1</th>\n",
              "      <th>x2</th>\n",
              "      <th>y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   x1  x2  y\n",
              "0   0   0  1\n",
              "1   1   0  1\n",
              "2   0   1  1\n",
              "3   1   1  0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HlEZ3UzK8Z_e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "inputs = np.array([\n",
        "                  [0,0],\n",
        "                  [1,1],\n",
        "                  [1,0],\n",
        "                  [0,1]                   \n",
        "\n",
        "])\n",
        "\n",
        "correct_outputs = [[1], [1], [1], [0]]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZjUZxDBe-Xw2",
        "colab_type": "text"
      },
      "source": [
        "Sigmoid activation function and its derivative for updating weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "TRuX3DDsgbAk",
        "colab": {}
      },
      "source": [
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "def sigmoid_derivative(x):\n",
        "    sx = sigmoid(x)\n",
        "    return sx * (1-sx)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FcS07nAb-gle",
        "colab_type": "text"
      },
      "source": [
        "Initialize random weights for our three inputs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gcEXbLYv8Z_0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "weights = np.random.random((2,1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y_rDReNt8aAE",
        "colab_type": "code",
        "outputId": "c61762d6-383b-451f-aacb-ffb6e2a21a8e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "weights"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.28825648],\n",
              "       [0.8356776 ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uvnH6EHZ-Qr-",
        "colab_type": "text"
      },
      "source": [
        "Calculate weighted sum of inputs and weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gt6rzoQw8aAQ",
        "colab_type": "code",
        "outputId": "4e332545-64ff-405f-8a4b-55e231475f4a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "weighted_sum = np.dot(inputs, weights)\n",
        "weighted_sum"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.        ],\n",
              "       [1.12393408],\n",
              "       [0.28825648],\n",
              "       [0.8356776 ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KcJ6EtsR-tKG",
        "colab_type": "text"
      },
      "source": [
        "Output the activated value for the end of 1 training epoch "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bDQvOOuK8aAZ",
        "colab_type": "code",
        "outputId": "fe77e802-c26b-4646-d942-af33618301ec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "activated_output = sigmoid(weighted_sum)\n",
        "activated_output"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.5       ],\n",
              "       [0.75471772],\n",
              "       [0.57156924],\n",
              "       [0.69755409]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ryp1La8-wHo",
        "colab_type": "text"
      },
      "source": [
        "take difference of output and true values to calculate error"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yiEyy7iQ-zsG",
        "colab_type": "code",
        "outputId": "5d2646d4-7967-47b3-95c9-47604f84977c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "error = correct_outputs - activated_output\n",
        "error"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.5       ],\n",
              "       [ 0.24528228],\n",
              "       [ 0.42843076],\n",
              "       [-0.69755409]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HGDdi_hb_HOb",
        "colab_type": "text"
      },
      "source": [
        "Gradient descent/backprop - magic!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eeh59e67_Jt6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "adjustments = error * sigmoid_derivative(weighted_sum)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zxz3Weab_JV4",
        "colab_type": "code",
        "outputId": "cefb3378-59db-44d0-f038-73278f5da741",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "weights += np.dot(inputs.T, adjustments)\n",
        "weights"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.43857607],\n",
              "       [0.73391933]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_KhKMk8I_haQ",
        "colab_type": "text"
      },
      "source": [
        "Put it all together"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ru2Keymb_dQk",
        "colab_type": "code",
        "outputId": "a1c54124-ce78-4e73-e6c1-9839877bad0d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        }
      },
      "source": [
        "# Steps we've already done: \n",
        "# 1. Randomly Initialized Weights already. Those are in memory as `weights`\n",
        "# 2. We've already got input data & correct_outputs\n",
        "\n",
        "\n",
        "# Update our weights 10,000 times - (fingers crossed that this process reduces error)\n",
        "for iteration in range(1000):\n",
        "    \n",
        "    # Weighted sum of inputs / weights\n",
        "    weighted_sum = np.dot(inputs, weights)\n",
        "    \n",
        "    # Activate!\n",
        "    activated_output = sigmoid(weighted_sum)\n",
        "    \n",
        "    # Cac error\n",
        "    error = correct_outputs - activated_output\n",
        "    \n",
        "    adjustments = error * sigmoid_derivative(weighted_sum)\n",
        "    \n",
        "    # Update the Weights\n",
        "    weights += np.dot(inputs.T, adjustments)\n",
        "    \n",
        "print(\"Weights after training\")\n",
        "print(weights)\n",
        "\n",
        "print(\"Output after training\")\n",
        "print(activated_output)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Weights after training\n",
            "[[ 6.49612278]\n",
            " [-3.13983072]]\n",
            "Output after training\n",
            "[[0.5       ]\n",
            " [0.96629249]\n",
            " [0.99849134]\n",
            " [0.0415159 ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Xf7sdqVs0s4x"
      },
      "source": [
        "## Implement your own Perceptron Class and use it to classify a binary dataset: \n",
        "- [The Pima Indians Diabetes dataset](https://raw.githubusercontent.com/ryanleeallred/datasets/master/diabetes.csv) \n",
        "\n",
        "You may need to search for other's implementations in order to get inspiration for your own. There are *lots* of perceptron implementations on the internet with varying levels of sophistication and complexity. Whatever your approach, make sure you understand **every** line of your implementation and what its purpose is."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "huaiWuJggYM7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rYzmNhyH8aAp",
        "colab_type": "code",
        "outputId": "8f36e6d5-597f-41ba-e371-4ae4d3bbf00c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "source": [
        "diabetes = pd.read_csv('https://raw.githubusercontent.com/ryanleeallred/datasets/master/diabetes.csv')\n",
        "diabetes.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Pregnancies</th>\n",
              "      <th>Glucose</th>\n",
              "      <th>BloodPressure</th>\n",
              "      <th>SkinThickness</th>\n",
              "      <th>Insulin</th>\n",
              "      <th>BMI</th>\n",
              "      <th>DiabetesPedigreeFunction</th>\n",
              "      <th>Age</th>\n",
              "      <th>Outcome</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6</td>\n",
              "      <td>148</td>\n",
              "      <td>72</td>\n",
              "      <td>35</td>\n",
              "      <td>0</td>\n",
              "      <td>33.6</td>\n",
              "      <td>0.627</td>\n",
              "      <td>50</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>85</td>\n",
              "      <td>66</td>\n",
              "      <td>29</td>\n",
              "      <td>0</td>\n",
              "      <td>26.6</td>\n",
              "      <td>0.351</td>\n",
              "      <td>31</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8</td>\n",
              "      <td>183</td>\n",
              "      <td>64</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>23.3</td>\n",
              "      <td>0.672</td>\n",
              "      <td>32</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>89</td>\n",
              "      <td>66</td>\n",
              "      <td>23</td>\n",
              "      <td>94</td>\n",
              "      <td>28.1</td>\n",
              "      <td>0.167</td>\n",
              "      <td>21</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>137</td>\n",
              "      <td>40</td>\n",
              "      <td>35</td>\n",
              "      <td>168</td>\n",
              "      <td>43.1</td>\n",
              "      <td>2.288</td>\n",
              "      <td>33</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Pregnancies  Glucose  BloodPressure  ...  DiabetesPedigreeFunction  Age  Outcome\n",
              "0            6      148             72  ...                     0.627   50        1\n",
              "1            1       85             66  ...                     0.351   31        0\n",
              "2            8      183             64  ...                     0.672   32        1\n",
              "3            1       89             66  ...                     0.167   21        0\n",
              "4            0      137             40  ...                     2.288   33        1\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-qLUSleJ8aA7",
        "colab_type": "text"
      },
      "source": [
        "Although neural networks can handle non-normalized data, scaling or normalizing your data will improve your neural network's learning speed. Try to apply the sklearn `MinMaxScaler` or `Normalizer` to your diabetes dataset. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OqP1sydp8aBB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import MinMaxScaler, Normalizer\n",
        "\n",
        "features = list(diabetes)[:-1]\n",
        "target = list(diabetes)[-1:]\n",
        "# Instantiate normalizer\n",
        "normalizer = Normalizer()\n",
        "\n",
        "# Normalize the feature data\n",
        "X = normalizer.fit_transform(diabetes[features])\n",
        "# Set target vector\n",
        "y = diabetes[target]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E8e_L6EpIUg1",
        "colab_type": "code",
        "outputId": "f184adb3-b18c-463e-f999-9a9bd47f2d97",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256
        }
      },
      "source": [
        "X"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.03355237, 0.82762513, 0.40262844, ..., 0.18789327, 0.00350622,\n",
              "        0.27960308],\n",
              "       [0.008424  , 0.71604034, 0.55598426, ..., 0.22407851, 0.00295683,\n",
              "        0.26114412],\n",
              "       [0.04039768, 0.92409698, 0.32318146, ..., 0.11765825, 0.00339341,\n",
              "        0.16159073],\n",
              "       ...,\n",
              "       [0.02691539, 0.65135243, 0.38758161, ..., 0.14103664, 0.00131885,\n",
              "        0.16149234],\n",
              "       [0.00665306, 0.83828547, 0.39918356, ..., 0.20025708, 0.00232192,\n",
              "        0.31269379],\n",
              "       [0.00791454, 0.73605211, 0.55401772, ..., 0.24060198, 0.00249308,\n",
              "        0.18203439]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3YwzeAjdIRcd",
        "colab_type": "code",
        "outputId": "0932bfc0-1146-4929-f6b4-626dea091304",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "source": [
        "y.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Outcome</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Outcome\n",
              "0        1\n",
              "1        0\n",
              "2        1\n",
              "3        0\n",
              "4        1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M3-yhhm9H2Ny",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ly5WgQswfTS6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Perceptron:\n",
        "    \n",
        "    def __init__(self, niter = 10):\n",
        "        self.niter = niter\n",
        "    \n",
        "    def sigmoid(self, x):\n",
        "        return 1 / (1 + np.exp(-x))\n",
        "    \n",
        "    def sigmoid_derivative(self, x):\n",
        "        sx = sigmoid(x)\n",
        "        return sx * (1-sx)\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        \"\"\"Fit training data\n",
        "        X : Training vectors, X.shape : [#samples, #features]\n",
        "        y : Target values, y.shape : [#samples]\n",
        "        \"\"\"\n",
        "        # Randomly Initialize Weights\n",
        "        self.weight = 2 * np.random.random((8,1)) - 1\n",
        "\n",
        "        for i in range(self.niter):\n",
        "            # Weighted sum of inputs / weights\n",
        "            weighted_sum = np.dot(X, self.weight) + 1\n",
        "            # Activate!\n",
        "            activated_output = self.sigmoid(weighted_sum)\n",
        "            # Cac error\n",
        "            error = y - activated_output\n",
        "            adjustments = error * self.sigmoid_derivative(weighted_sum)\n",
        "            # Update the Weights\n",
        "            self.weight = self.weight + np.dot(X.T, adjustments)\n",
        "\n",
        "        return self\n",
        "    \n",
        "    \n",
        "    def predict(self, X):\n",
        "        \"\"\"Return class label after unit step\"\"\"\n",
        "        weighted_sum = np.dot(X, self.weight) + 1\n",
        "        activated_output = self.__sigmoid(weighted_sum)\n",
        "        return np.round(activated_output)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dC3Kt6U1pIEb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rNGnSiRNfxKD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Perceptron()\n",
        "model.fit(X, y)\n",
        "model.predict(X)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nLtN3alWoVPI",
        "colab_type": "code",
        "outputId": "4e558d31-54ef-4927-b3d8-08a3130a0ab7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        }
      },
      "source": [
        "from sklearn.linear_model import LogisticRegressionCV\n",
        "\n",
        "lr = LogisticRegressionCV(cv=5, multi_class='multinomial')\n",
        "lr.fit(X_train, y_train)\n",
        "lr.score(X_test,y_test) # Basically a random guess"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.640625"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "6QR4oAW1xdyu"
      },
      "source": [
        "## Stretch Goals:\n",
        "\n",
        "- Research \"backpropagation\" to learn how weights get updated in neural networks (tomorrow's lecture). \n",
        "- Implement a multi-layer perceptron. (for non-linearly separable classes)\n",
        "- Try and implement your own backpropagation algorithm.\n",
        "- What are the pros and cons of the different activation functions? How should you decide between them for the different layers of a neural network?"
      ]
    }
  ]
}